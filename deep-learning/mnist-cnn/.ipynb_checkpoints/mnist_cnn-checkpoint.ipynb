{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer (Kaggle), 0.991 Accuracy with Keras\n",
    "<hr>\n",
    "In this tutorial we are going to use __*Convolutional Neural Networks*__ to classify images from the __*MNIST*__ dataset.\n",
    "\n",
    "- You can find the competition [here](https://www.kaggle.com/c/digit-recognizer/data)\n",
    "- Blog post [here](https://thelastdev.com/2018/07/09/digit-recognizer-kaggle-0-991-accuracy-with-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "%pylab inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import numpy.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the dataset\n",
    "After downloading the dataset, we are going to do the following:\n",
    "\n",
    "1. Open the file and load the data\n",
    "2. Format the data and get the labels\n",
    "3. Check for NaN values\n",
    "4. Split the dataset to train and validation\n",
    "5. Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_train_data(path):\n",
    "    \n",
    "    train = [] \n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lines = list(reader)\n",
    "        for line in tqdm(lines[1:]):\n",
    "            label = line[0]\n",
    "            \n",
    "            image = np.array([x for x in line[1:]])\n",
    "            image = image.astype('float32')\n",
    "            \n",
    "            # Format the data to 28x28x1 (in grey scale)\n",
    "            image = np.reshape(image, (28, 28, 1))\n",
    "            train.append([image, label])\n",
    "    \n",
    "    return np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(train):\n",
    "    \n",
    "    np.random.shuffle(train)\n",
    "    \n",
    "    features = [x[0] for x in train]\n",
    "    labels = [x[1] for x in train]\n",
    "    \n",
    "    # Split the dataset to train and validation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.025, random_state=42)\n",
    "    \n",
    "    # One-hot Encoding\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    return (np.array(x_train), y_train), (np.array(x_test), y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, run only once\n",
    "# train = open_train_data('dataset/train.csv')\n",
    "# np.save('train.npy', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have already ran the the function open_train_data then run this\n",
    "train = np.load('train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "import pandas as pd\n",
    "\n",
    "for idx, feature in enumerate(train):\n",
    "    if pd.isnull(feature).any():\n",
    "        print('Found NaN value in feature %d' % idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = split_train_test(train)\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "batch_size = 64\n",
    "\n",
    "opt_rms = keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# opt_rms = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt_rms, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "epochs = 100\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph/{}'.format(time()), histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.h5', verbose=1, monitor='val_acc', save_best_only=True, mode='auto')\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tbCallBack, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('<your model .h5 here>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "def open_test_data(path):\n",
    "    \n",
    "    test = [] \n",
    "    \n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        lines = list(reader)\n",
    "        image_number = 1\n",
    "        for line in tqdm(lines[1:]):\n",
    "            \n",
    "            image = np.array([x for x in line])\n",
    "            image = image.astype('float32')\n",
    "            image = np.reshape(image, (28, 28, 1))\n",
    "            test.append([image, image_number])\n",
    "            image_number += 1\n",
    "    \n",
    "    return np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = open_test_data('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('test.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('ImageId,Label\\n')\n",
    "    for data in tqdm(test_data):\n",
    "        arr = numpy.expand_dims(data[0], axis=0)\n",
    "        number = model.predict(arr)\n",
    "        \n",
    "        label = argmax(number)\n",
    "        f.write(str(data[1]) + ',' + str(label) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow-gpu)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
